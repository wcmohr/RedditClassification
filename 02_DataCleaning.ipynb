{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "72ea56c7-2158-44b4-a906-b10f8b4b1a67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/william/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import (train_test_split, cross_val_predict, \n",
    "cross_val_score)\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import BaggingRegressor, StackingRegressor, StackingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#NLP Libs\n",
    "import re\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from cleantext import clean\n",
    "import xgboost\n",
    "\n",
    "# Lemmatizing Libs\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378acf65-61ef-482a-ac04-7b80ef01ee36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### Import, cleaning, traint test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688c439b-a8fb-48b6-b00d-ff5151e6d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = glob.glob('./scitech_data_scraped/*.csv') #\n",
    "latest_file = max(list_of_files, key=os.path.getctime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbb39fdd-c4cb-4a78-bf90-0b294b238198",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/william/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (17,21,34,63,68,112) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "sci_tech_data = pd.read_csv(latest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce600eb6-498d-4778-a693-33f8982b78ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows.\n",
    "sci_tech_data.drop_duplicates(subset = ['selftext','title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0afe67e9-f4ff-4e02-aff8-0732016ec923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select rows with tech or science as the subreddits and save the feature space, \n",
    "# 'title' and the target, 'subreddit' to respective variables.\n",
    "\n",
    "subreddit = sci_tech_data.loc[(sci_tech_data['subreddit'].isin(\n",
    "                                ['technology','science']), 'subreddit')]\n",
    "title = sci_tech_data.loc[(sci_tech_data['subreddit'].isin(\n",
    "                                ['technology','science']),'title')]\n",
    "# Set X and y\n",
    "X = title\n",
    "y = subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "844a5dd4-2153-4c53-950e-9a2739fbc635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, \n",
    "                                                    stratify=y)\n",
    "# Re-index to allow for easy splicing\n",
    "(X_train.index, y_train.index, X_test.index, y_test.index) = \\\n",
    "(range(0, X_train.shape[0]),range(0, X_train.shape[0]), \\\n",
    " range(0, X_test.shape[0]),range(0, X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e5d92e-b6c0-4a93-8394-f0df222958f8",
   "metadata": {},
   "source": [
    "[remove stop words](https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b604a817-dff0-4876-872c-82092263fc74",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'technology',\n",
       " 'science']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english') + ['technology', 'science']\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e57824bc-b44f-4287-8a48-b314aa1ce2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered(data):\n",
    "    # replace \"-\" w/ 'hyphen', then remove emojis, punctuation, digits, and urls\n",
    "    # while keeping an indicator or url usage.\n",
    "    data_filtered = data.map(lambda x: clean(\n",
    "                            re.sub('-',repl=' hyphen ', string = x) , no_emoji=True,\n",
    "                                no_punct=True,no_digits=True, no_urls=True))\n",
    "\n",
    "    # remove leftovers from the 'clean' function  \n",
    "\n",
    "    data_filtered = data_filtered.map(lambda x: re.sub('(0|\\|)',\n",
    "                                                    repl='',string = x))\n",
    "    #replacing hyphen with '-'\n",
    "    data_filtered = data_filtered.map(lambda x: re.sub('hyphen',repl='-', string = x))\n",
    "    # remove stop words   \n",
    "    data_filtered = data_filtered.map(lambda x: ' '.join([word for word \n",
    "                                              in x.split() if word not in \n",
    "                                              stop_words]))\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "35f57f34-bb61-408e-b60d-1075d5900e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtered = filtered(X_train)\n",
    "X_test_filtered = filtered(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcc70fe-61c5-4114-9ef1-0f21da239003",
   "metadata": {},
   "source": [
    "[how to get latest file](https://stackoverflow.com/questions/39327032/how-to-get-the-latest-file-in-a-folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2660d309-13e8-4f33-8ab0-fcfc6824a589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7392,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51cd508-78ba-467a-928e-a10e9c94b40a",
   "metadata": {},
   "source": [
    "I'll get POS counts on the raw data.\n",
    "[dict to df](https://sparkbyexamples.com/python/pandas-convert-list-of-dictionaries-to-dataframe/#:~:text=The%20from_records()%20method%20is,dicts%20%2C%20or%20from%20another%20DataFrame.); \n",
    "[spacy POS tagging](https://machinelearningknowledge.ai/tutorial-on-spacy-part-of-speech-pos-tagging/); [spacy POS tagging #2](https://www.geeksforgeeks.org/python-pos-tagging-and-lemmatization-using-spacy/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f222fad-1820-401d-8a10-36973fe6229c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Proving',\n",
       " 'a',\n",
       " 'point:',\n",
       " '+|-',\n",
       " 'karma',\n",
       " 'has',\n",
       " 'nothing',\n",
       " 'to',\n",
       " 'do',\n",
       " 'with',\n",
       " 'quality',\n",
       " 'of',\n",
       " 'post']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd022fc-68ef-4864-9db6-922bb44a718c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee750be2-5ee3-401d-b834-2b169391a716",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e239a59-de19-4565-8838-604da49a6092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(titles):\n",
    "    '''tokenize a 1d object containing strings, returning a list of lists of \n",
    "    tokenized words'''\n",
    "    \n",
    "    tokenized = []\n",
    "    \n",
    "    for title in titles:\n",
    "        tokenized.append(nlp(title))\n",
    "        \n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8980cca-3570-416e-8937-1fe3f6b1d9d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_tokens = tokenize(X_train)\n",
    "X_test_tokens = tokenize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32dd7704-0a5a-4785-b719-76c2e04d8644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_features(tokenized):\n",
    "    '''get the stats features that will be used in predicting, returned as a \n",
    "    sorted dictionary with keys as spacy parts of speech and fine pos tags'''\n",
    "    features = []\n",
    "    for tokens in tokenized:\n",
    "        for token in tokens:\n",
    "            if token.pos_ not in features:\n",
    "                features.append(token.pos_)\n",
    "            if token.tag_ not in features:\n",
    "                features.append(token.tag_)\n",
    "    return dict(zip(sorted(features),np.zeros(len(features)).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "962dab07-7c94-4edc-8a85-d0b8068570c1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$': 0,\n",
       " \"''\": 0,\n",
       " ',': 0,\n",
       " '-LRB-': 0,\n",
       " '-RRB-': 0,\n",
       " '.': 0,\n",
       " ':': 0,\n",
       " 'ADD': 0,\n",
       " 'ADJ': 0,\n",
       " 'ADP': 0,\n",
       " 'ADV': 0,\n",
       " 'AFX': 0,\n",
       " 'AUX': 0,\n",
       " 'CC': 0,\n",
       " 'CCONJ': 0,\n",
       " 'CD': 0,\n",
       " 'DET': 0,\n",
       " 'DT': 0,\n",
       " 'EX': 0,\n",
       " 'FW': 0,\n",
       " 'HYPH': 0,\n",
       " 'IN': 0,\n",
       " 'INTJ': 0,\n",
       " 'JJ': 0,\n",
       " 'JJR': 0,\n",
       " 'JJS': 0,\n",
       " 'LS': 0,\n",
       " 'MD': 0,\n",
       " 'NFP': 0,\n",
       " 'NN': 0,\n",
       " 'NNP': 0,\n",
       " 'NNPS': 0,\n",
       " 'NNS': 0,\n",
       " 'NOUN': 0,\n",
       " 'NUM': 0,\n",
       " 'PART': 0,\n",
       " 'PDT': 0,\n",
       " 'POS': 0,\n",
       " 'PRON': 0,\n",
       " 'PROPN': 0,\n",
       " 'PRP': 0,\n",
       " 'PRP$': 0,\n",
       " 'PUNCT': 0,\n",
       " 'RB': 0,\n",
       " 'RBR': 0,\n",
       " 'RBS': 0,\n",
       " 'RP': 0,\n",
       " 'SCONJ': 0,\n",
       " 'SPACE': 0,\n",
       " 'SYM': 0,\n",
       " 'TO': 0,\n",
       " 'UH': 0,\n",
       " 'VB': 0,\n",
       " 'VBD': 0,\n",
       " 'VBG': 0,\n",
       " 'VBN': 0,\n",
       " 'VBP': 0,\n",
       " 'VBZ': 0,\n",
       " 'VERB': 0,\n",
       " 'WDT': 0,\n",
       " 'WP': 0,\n",
       " 'WP$': 0,\n",
       " 'WRB': 0,\n",
       " 'X': 0,\n",
       " 'XX': 0,\n",
       " '_SP': 0,\n",
       " '``': 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_features = get_pos_features(X_train_tokens)\n",
    "pos_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ec90771a-f353-4387-8b69-1862533ef173",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "logreg = LogisticRegressionCV(max_iter=10_000)\n",
    "pipe_lr = Pipeline([\n",
    "    ('ss',ss),\n",
    "    ('lr',logreg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5814d1f2-cd90-4271-8024-ec1cce1dfd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ss&#x27;, StandardScaler()),\n",
       "                (&#x27;lr&#x27;, LogisticRegressionCV(max_iter=10000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ss&#x27;, StandardScaler()),\n",
       "                (&#x27;lr&#x27;, LogisticRegressionCV(max_iter=10000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(max_iter=10000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ss', StandardScaler()),\n",
       "                ('lr', LogisticRegressionCV(max_iter=10000))])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr.fit(X_train_stats,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "05e84355-7e6b-452c-99a5-b441eab999c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7955898268398268, 0.797971602434077)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr.score(X_train_stats,y_train), pipe_lr.score(X_test_stats,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7d71ce84-bd55-4772-ad39-9536c8e3a5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/william/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but LogisticRegressionCV was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 1.71218293e-116],\n",
       "       [1.00000000e+000, 7.53822428e-130],\n",
       "       ...,\n",
       "       [1.00000000e+000, 1.69389133e-106],\n",
       "       [1.00000000e+000, 2.62290047e-141],\n",
       "       [1.00000000e+000, 9.93644186e-133]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr['lr'].predict_proba(X_test_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f4620266-adc3-4955-824c-9629fa8bd81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV(max_iter=10000)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_stats,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b0042707-1617-4d30-b690-a8fa2f89e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_stats(titles, tokenized, pos_feat_dict):\n",
    "    features = pos_feat_dict\n",
    "    '''generate title statistics from a 1d object of title and return as a \n",
    "    DataFrame '''\n",
    "    \n",
    "    # Char length, word count, max and avg word length\n",
    "    title_stats = pd.DataFrame()\n",
    "    title_stats['title_length'] = [len(titles[i]) for i in range(len(titles))]\n",
    "    title_stats['title_word_count'] = [len(titles[i].split(' ')) for \\\n",
    "                                        i in range(len(titles))]\n",
    "    title_stats['max_word_length'] = [max(map(len, title.split(' '))) \\\n",
    "                         for title in titles]\n",
    "    title_stats['avg_word_length'] = title_stats['title_length']/title_stats['title_word_count']\n",
    "    \n",
    "    # POS counts, fine pos tag counts    \n",
    "    parts_of_speech = []\n",
    "    for tokens in tokenized:\n",
    "        pos_counts = dict(features)\n",
    "        for token in tokens:\n",
    "            pos_counts[token.pos_] += 1\n",
    "            pos_counts[token.tag_] += 1\n",
    "        parts_of_speech.append(pos_counts)\n",
    "    # combine \n",
    "    pos_df = pd.DataFrame(parts_of_speech).fillna(0)\n",
    "    # pos_props_df = pos_df.iloc[:,4:].div(title_stats.title_word_count,axis=0).add_prefix(\"prop_\")\n",
    "    \n",
    "    tstats_pos = pd.concat([title_stats, pos_df],axis = 1)\n",
    "    return  tstats_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a0cbc-c601-485e-a82c-c47fb5531484",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### **Lemmatization** -- [sources](https://www.machinelearningplus.com/nlp/lemmatization-examples-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9179e519-961b-454e-b7e8-4a2d4aae7eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/william/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6218a8a5-05f8-4815-abf0-9790941b5555",
   "metadata": {},
   "source": [
    "[Lemmatizing w/ POS](https://www.machinelearningplus.com/nlp/lemmatization-examples-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a6514145-4e90-480c-bf69-a7656d9834ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lemmatize with POS Tag\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de2616f-defc-49f2-8a9b-2b5f1c1b6b39",
   "metadata": {},
   "source": [
    "To-do/idea: get POS counts [source](https://stackoverflow.com/questions/20960777/python-how-to-count-pos-tags-from-from-a-sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "89443d51-5586-451a-a480-b8cd235bfebf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              prove point + - karma nothing quality post\n",
       "1        researcher identify origin serious illness child\n",
       "2               way go level human need - think ai take u\n",
       "3       former amazon exec reportedly paid $ run jeff ...\n",
       "4       iphone pro max gb alpine green - unlocked rene...\n",
       "                              ...                        \n",
       "7387    supergps accurately pinpoint position within i...\n",
       "7388                 email scrap legal - resistancephlcom\n",
       "7389    amazon ceo prime video attractive economics pa...\n",
       "7390               possible native payment system twitter\n",
       "7391    new study base foi request page found coca - c...\n",
       "Length: 7392, dtype: object"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "# Lemmatize train\n",
    "X_train_lemmatized = []\n",
    "for title in X_train_filtered:\n",
    "    X_train_lemmatized.append(' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for \\\n",
    "                               w in nltk.word_tokenize(title)]))\n",
    "X_train_lemmatized = pd.Series(data = X_train_lemmatized, index = X_train_filtered.index)\n",
    "X_train_lemmatized\n",
    "\n",
    "# Lemmatize test\n",
    "X_test_lemmatized = []\n",
    "for title in X_test_filtered:\n",
    "    X_test_lemmatized.append(' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for \\\n",
    "                               w in nltk.word_tokenize(title)]))\n",
    "X_test_lemmatized = pd.Series(data = X_test_lemmatized, index = X_test_filtered.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "08167d63-0b92-4480-b7cd-c755718b3e76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'traffic related air pollution associate increase likelihood multiple long - term physical mental health condition research people found simple measure reduce traffic level could potentially improve life lessen pressure healthcare system'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903b0398-83c8-40c6-9e55-2278e748c4cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e4c2b3-fd10-4d67-92cd-6ebf4cc6e442",
   "metadata": {},
   "source": [
    "Below I will inspect various distributions of title statistics after adding the statistics to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7a3422-2f13-4e0e-8502-f52042f01889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame from the lemmatized series\n",
    "df = pd.DataFrame(X_train_lemmatized, columns = ['title']).join(pd.DataFrame(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed19be-f89c-4410-96b0-ed432e2e60c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(X_test_lemmatized, columns = ['title']).join(pd.DataFrame(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f497e187-8c16-4dc0-95d9-aa7cf27e3a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = range(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6412d977-d0e5-4dda-83eb-d47b9fa08b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['title_length'] = [len(df.loc[i,'title']) for i in range(len(df['title']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a357d8c6-8480-41d8-8d57-93619f12f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_word_count'] = [len(df.loc[i,'title'].split(' ')) for i in range(len(df['title']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e020abad-5b48-4808-9ef5-a39e9ad72dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['max_word_length'] = [max(map(len, title.split(' '))) \\\n",
    "                         for title in df['title']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb4cff3-0ea8-4c6e-83e0-ab9fe1081e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_word_length'] = df['title_length']/df['title_word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786928bc-fcf4-477b-a581-b3e5657558db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subreddit_indicator']=[1 if sub == 'technology' else 0 for sub in df['subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b9a14-684f-4625-9517-170464c8dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe945764-9d92-4ab2-b564-bc2314a40752",
   "metadata": {},
   "source": [
    "###### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9de48-b142-47bb-87e5-820e11fa642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = df, x = 'title_word_count', hue = 'subreddit', stat='density', common_norm = False, bins = 45).set(title = 'Distribution of title word counts by subreddit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447637c2-20a2-4ce3-98db-5a2919868f32",
   "metadata": {},
   "source": [
    "Above we can see that shorter titles have a better chance of having been posted to technology, while longer titles are more likely from science even after accounting for baseline frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ac4d71-7db1-4cb4-90d1-2fdef8a44d48",
   "metadata": {},
   "source": [
    "Above we see that there are many posts between 0 and 20 words long with a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6373fb51-2c1c-4290-91fb-c70555e8a010",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = df, x = 'title_length', hue = 'subreddit', stat='density', common_norm = False).set(title = 'Distribution of title character length by subreddit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f836a7b2-5af2-43e4-9068-21ce86d5e1c3",
   "metadata": {},
   "source": [
    "Above we see that generally title character lengths under around 80 are more likely to have been from technology, and above 80 from science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6a490f-d777-429d-89ad-f3cf3d3bfce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = df, x = 'avg_word_length', hue = 'subreddit', \n",
    "             stat='density', bins = 100, common_norm = False).set(\n",
    "    title = 'Distribution of title word counts by subreddit', xlim = [4,11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ca38b8-8056-411a-9bd1-266b08e80f9b",
   "metadata": {},
   "source": [
    "[adjusting bins](https://stackoverflow.com/questions/48990594/how-to-draw-distribution-plot-for-discrete-variables-in-seaborn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5d56e6-3d23-4715-8f37-922069b4b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = df, x = 'max_word_length', hue = 'subreddit', \n",
    "             stat='density', common_norm = False, bins=np.arange(0,21)).set(\n",
    "    title = 'Distribution of title word counts by subreddit', xlim = [0,20], \n",
    "    xticks = range(0,21));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcd8a8b-ff98-4d9d-a21f-a550cf4552bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c385bd3-190c-4b8c-a7b2-a1ffe31b5c6d",
   "metadata": {},
   "source": [
    "Above we see that word length, character count, and word counts all have some correlation with the particular subredit, though the correlation is not strong.  However, from the density plots and the clear separation in likelihoods it is apparent that valuable information would likely be picked up from a tree-based classification model.  It is promising that the title statistics gathered thus far are not fully correlated with each other as this means they can provide non-redundant information to the modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc012395-1921-4bfa-a23d-11be292bb07b",
   "metadata": {},
   "source": [
    "I'll next look at word count frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b4d65-7090-4e45-9dab-cd14f9817ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "vectors = cv.fit_transform(df[df['subreddit']=='technology']['title'])\n",
    "vectors.A\n",
    "wc_vec = pd.DataFrame(vectors.A, columns = cv.get_feature_names_out())\n",
    "wc_vec.sum().sort_values(ascending = False)[0:15].plot(kind = 'bar')\\\n",
    ".set(title = '15 most common words word count -- technology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb79fd7b-647e-4e4b-9f6e-2b1426a96c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "vectors = cv.fit_transform(df[df['subreddit']=='science']['title'])\n",
    "vectors.A\n",
    "wc_vec = pd.DataFrame(vectors.A, columns = cv.get_feature_names_out())\n",
    "wc_vec.sum().sort_values(ascending = False)[0:15].plot(kind = 'bar')\\\n",
    ".set(title = '15 most common words word count -- science')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185bd6d-4c61-45c7-9cf3-8baa5ec86349",
   "metadata": {},
   "source": [
    "Above we see that there is not much overlap within the 15 most common words.  This indicates that there is a good chance that these common words will help with distinguishing between the subreddits.  Of note is that proper nouns seem to feature heavily in technology and almost not at all in science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d0e51-85f6-4d78-ba8b-01245080091c",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2c7a74-7b24-46b6-8505-d407e3d955f2",
   "metadata": {},
   "source": [
    "The idea is to use a stacked model with one model using the vecotrized/lemmatized titles and the other using the title statistics as the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f74d4d-4d05-4b9b-95f7-041fab9de433",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### Iterative improvement ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0707a-5d54-4e0f-ba8d-2bf259720cf9",
   "metadata": {},
   "source": [
    "Idea: combine these fuctionalities around the text data into a class with methods.\n",
    "Idea: a class that grid search optimizes functions in the background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a224be-a9fa-4ebe-9b03-0b44e86b9f96",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3006a19e-57f0-4e99-a933-88eab7f91c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6791075050709939"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc = DummyClassifier()\n",
    "dc.fit(X_train,y_train)\n",
    "dc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a5f3d6-8bf4-4415-884e-af01691eab97",
   "metadata": {},
   "source": [
    "The baseline model accuracy is 67.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1750ff-b311-47b2-ac40-aaa857a1583d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### binary target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "c55c4116-32bf-44a7-b4e1-5a49f0fe14a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary format for XGB target\n",
    "y_train_binary = [1 if sub == 'technology' else 0 for sub in y_train]\n",
    "y_test_binary = [1 if sub == 'technology' else 0 for sub in y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f14047-4736-43ea-b0a1-86f20b32ddac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### modeling on statistics of the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "7bba6a74-9b7a-48bc-b37b-0bc77a2f6744",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stats = get_title_stats(X_train,X_train_tokens,pos_features)\n",
    "X_test_stats = get_title_stats(X_test,X_test_tokens,pos_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "ab153b68-bbf9-4b53-b8ed-8b69b63d6c96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-48 {color: black;background-color: white;}#sk-container-id-48 pre{padding: 0;}#sk-container-id-48 div.sk-toggleable {background-color: white;}#sk-container-id-48 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-48 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-48 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-48 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-48 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-48 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-48 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-48 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-48 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-48 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-48 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-48 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-48 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-48 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-48 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-48 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-48 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-48 div.sk-item {position: relative;z-index: 1;}#sk-container-id-48 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-48 div.sk-item::before, #sk-container-id-48 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-48 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-48 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-48 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-48 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-48 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-48 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-48 div.sk-label-container {text-align: center;}#sk-container-id-48 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-48 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-48\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-91\" type=\"checkbox\" checked><label for=\"sk-estimator-id-91\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier()\n",
    "xgb.fit(X_train_stats, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "9b9ceb73-c92a-4120-a34e-dc2242577e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9296536796536796, 0.8068965517241379)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.score(X_train_stats, y_train_binary), xgb.score(X_test_stats, y_test_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e5c347-23f2-4703-8d4f-c4567701515d",
   "metadata": {},
   "source": [
    "The initial model of the score indicates substantial overfitting, so I will attempt to use random search to optimize the parameters max_depth, min_child_weight, gamma, subsample and colsample_bytree. [Control overfitting](https://xgboost.readthedocs.io/en/stable/tutorials/param_tuning.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "d7d5fb67-ecd4-4cb1-b464-d029eb7b8a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(1,6, num = 6).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ef9cb2-a2d8-41d6-ab28-c817e18972ff",
   "metadata": {},
   "source": [
    "[random search example](https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "de75ee6e-0b18-46b7-8197-dca6f302f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\n",
    "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                    results[\"mean_test_score\"][candidate],\n",
    "                    results[\"std_test_score\"][candidate],\n",
    "                )\n",
    "            )\n",
    "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf97212-9654-4891-88af-897e1fc093ab",
   "metadata": {},
   "source": [
    "searching with bayesian [hyperopt](https://grabngoinfo.com/hyperparameter-tuning-for-xgboost-grid-search-vs-random-search-vs-bayesian-optimization/) is a possible further exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "f77bb01f-f3cb-4f70-8d62-f16a0dc3e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier()\n",
    "param_dist = {\n",
    "              # 'booster': ['gbtree'],\n",
    "              'max_depth': np.linspace(1,6, num = 6).astype(int),\n",
    "              # 'min_child_weight': np.logspace(.01, 1, num = 3),\n",
    "              # 'gamma': np.logspace(.01, 1, num = 5),\n",
    "              # 'subsample': np.linspace(.5,1,num=4),\n",
    "              'colsample_bytree': np.linspace(.1,1,num=4)\n",
    "              }\n",
    "n_iter_search = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "37206a17-9890-4cc9-b116-14340c67d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    xgb, param_distributions=param_dist, n_iter=n_iter_search, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f34c0-884b-48f8-8311-72dd9b4b3e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "report(random_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "35ebb261-8b83-4e90-abcf-c14bb3317244",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-47 {color: black;background-color: white;}#sk-container-id-47 pre{padding: 0;}#sk-container-id-47 div.sk-toggleable {background-color: white;}#sk-container-id-47 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-47 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-47 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-47 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-47 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-47 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-47 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-47 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-47 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-47 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-47 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-47 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-47 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-47 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-47 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-47 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-47 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-47 div.sk-item {position: relative;z-index: 1;}#sk-container-id-47 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-47 div.sk-item::before, #sk-container-id-47 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-47 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-47 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-47 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-47 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-47 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-47 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-47 div.sk-label-container {text-align: center;}#sk-container-id-47 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-47 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-47\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None...\n",
       "                                           max_cat_threshold=None,\n",
       "                                           max_cat_to_onehot=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_iter=15, n_jobs=-1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: array([0.1, 0.4, 0.7, 1. ]),\n",
       "                                        &#x27;max_depth&#x27;: array([1, 2, 3, 4, 5, 6])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-88\" type=\"checkbox\" ><label for=\"sk-estimator-id-88\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None...\n",
       "                                           max_cat_threshold=None,\n",
       "                                           max_cat_to_onehot=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_iter=15, n_jobs=-1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: array([0.1, 0.4, 0.7, 1. ]),\n",
       "                                        &#x27;max_depth&#x27;: array([1, 2, 3, 4, 5, 6])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-89\" type=\"checkbox\" ><label for=\"sk-estimator-id-89\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-90\" type=\"checkbox\" ><label for=\"sk-estimator-id-90\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None...\n",
       "                                           max_cat_threshold=None,\n",
       "                                           max_cat_to_onehot=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_iter=15, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': array([0.1, 0.4, 0.7, 1. ]),\n",
       "                                        'max_depth': array([1, 2, 3, 4, 5, 6])})"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train_stats,y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "5a0f177f-40c8-492a-b7c3-37e0a3464840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.801 (std: 0.009)\n",
      "Parameters: {'max_depth': 3, 'colsample_bytree': 0.7}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.800 (std: 0.008)\n",
      "Parameters: {'max_depth': 4, 'colsample_bytree': 1.0}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.799 (std: 0.010)\n",
      "Parameters: {'max_depth': 4, 'colsample_bytree': 0.4}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "8a204b19-ce23-47a8-b93a-943eb57ed660",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.832521645021645, 0.8004056795131845)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.score(X_train_stats,y_train_binary),random_search.score(X_test_stats,y_test_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02c1614-729a-4929-aed1-0788ceb9a093",
   "metadata": {},
   "source": [
    "I have been unable to improve test performance through tuning the xgboost parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd3c6b-32a4-4a7b-a334-5aa8a463b0e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### Modeling on the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "10103726-2554-44f1-b2a1-8633dd0edd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_c_titles = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab4c386-e5ff-4c69-9726-8a12ada951bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_c_titles.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d56a19af-7f62-4714-a716-f2e8f7509c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(stop_words='english', max_features=1_000,\n",
    "                             ngram_range=(1,2))\n",
    "logreg = LogisticRegression(penalty='elasticnet', max_iter=10_000, \\\n",
    "                            random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573f98a-250a-438f-9b10-749dc016d84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "47eed92c-3ef1-453e-97b0-a34b4d15550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_lr_params = {\"logreg__C\": [.1,1,10],\n",
    "                    \"logreg__l1_ratio\": [.1,.5,.9],\n",
    "                   'tfidf_vec__max_df': [.9,.95,1.0],\n",
    "                   'tfidf_vec__min_df': [.001,.003]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ec7b4017-99fe-4e29-a162-4e964e3fafdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf_lr_pipe = Pipeline([\n",
    "    ('tfidf_vec', tfidf_vec),\n",
    "    ('logreg', LogisticRegression(penalty='none', max_iter=10_000, random_state=33))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3339779c-8b52-4de7-be6e-6c2aa940666f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf_vec&#x27;,\n",
       "                 TfidfVectorizer(max_features=1000, ngram_range=(1, 2),\n",
       "                                 stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(max_iter=10000, penalty=&#x27;none&#x27;,\n",
       "                                    random_state=33))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf_vec&#x27;,\n",
       "                 TfidfVectorizer(max_features=1000, ngram_range=(1, 2),\n",
       "                                 stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(max_iter=10000, penalty=&#x27;none&#x27;,\n",
       "                                    random_state=33))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000, ngram_range=(1, 2), stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, penalty=&#x27;none&#x27;, random_state=33)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf_vec',\n",
       "                 TfidfVectorizer(max_features=1000, ngram_range=(1, 2),\n",
       "                                 stop_words='english')),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(max_iter=10000, penalty='none',\n",
       "                                    random_state=33))])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_lr_pipe.fit(X_train_lemmatized, y_train_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "25a2254e-4e35-40e4-baa2-d563dd8b6675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8567951318458418"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_lr_pipe.score(X_test_lemmatized, y_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c7e2b-4641-49fc-b0d2-de767ec16e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_tfidf_lr = GridSearchCV(tfidf_lr_pipe,tfidf_lr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638744e9-b422-4545-a8cc-618fc4f66c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_tfidf_lr.score(X_test_lemmatized,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899943ca-b704-48f0-a271-e42a812c7c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_xgb_pipe = Pipeline([\n",
    "    ('tfidf_vec', tfidf_vec),\n",
    "    ('xgb', xgb.XGBClassifier())])\n",
    "tfidf_xgb_params = {\"xgb__eta\": [.01,.03],\n",
    "                    'xgb__booster': ['gbtree','gblinear'],\n",
    "                   'tfidf_vec__max_df': [.9,.95,1.0],\n",
    "                   'tfidf_vec__min_df': [.001,.003]}\n",
    "gs_tfidf_xgb = GridSearchCV(tfidf_xgb_pipe,tfidf_xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089f2df4-b070-41d4-b952-e54144905d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_tfidf_xgb.score(X_train_lemmatized,y_train_xgb),gs_tfidf_xgb.score(X_test_lemmatized,y_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe6b7a-70e7-4011-adfb-002d44b1e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_tfidf_xgb = GridSearchCV(tfidf_xgb_pipe,{'tfidf_vec__max_df': [0.9],\n",
    " 'tfidf_vec__min_df': [0.001],\n",
    " 'xgb__booster': ['gblinear'],\n",
    " 'xgb__eta': [0.01]})\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "75d753ef-5a35-4f06-81b0-039e4f1d55e0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1 if p =='technology' else 0 for p in rfc.predict(X_test_stats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5b2488e5-7790-4ba5-a312-346ef75d74e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9119318181818182, 0.8884381338742393)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gs_tfidf_xgb.fit(X_train_lemmatized,y_train_xgb)\n",
    "gs_tfidf_xgb.score(X_train_lemmatized,y_train_xgb),gs_tfidf_xgb.score(X_test_lemmatized,y_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f0f4d542-2ab3-4714-b899-885315b2d8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf_vec__max_df': 0.925,\n",
       " 'tfidf_vec__min_df': 0.001,\n",
       " 'xgb__booster': 'gblinear',\n",
       " 'xgb__eta': 0.01}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tfidf_xgb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ee304b-b760-4f17-89d0-0879be42afdd",
   "metadata": {},
   "source": [
    "param choices:\n",
    "tfidf_xgb_params = {\"xgb__eta\": [.01,.03],\n",
    "                    'xgb__booster': ['gbtree','gblinear'],\n",
    "                   'tfidf_vec__max_df': [.9,.95,1.0],\n",
    "                   'tfidf_vec__min_df': [.001,.003]}\n",
    "score: \n",
    "\n",
    "(0.9143668831168831, 0.8892494929006085)\n",
    "\n",
    "gs_tfidf_xgb.best_params_ :\n",
    "\n",
    "{'tfidf_vec__max_df': 0.9,\n",
    " 'tfidf_vec__min_df': 0.001,\n",
    " 'xgb__booster': 'gblinear',\n",
    " 'xgb__eta': 0.01}\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c91353e-fd36-42e9-bfb5-74b1dd12c877",
   "metadata": {},
   "source": [
    "So far xgboost has provided the best prediction on the test set.  I will try to narrow in on the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ade39f72-375b-42d1-b1f3-120e94649f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_xgb_pipe = Pipeline([\n",
    "    ('tfidf_vec', tfidf_vec),\n",
    "    ('xgb', xgb.XGBClassifier(seed = 1))])\n",
    "tfidf_xgb_params = {\"xgb__eta\": [.01,.015,.05],\n",
    "                    'xgb__booster': ['gbtree','gblinear'],\n",
    "                    # 'xgb__lambda': [.1,1,10],\n",
    "                    # 'xgb__alpha': [0,.1,1],\n",
    "                   'tfidf_vec__max_df': [.85,.9,.925],\n",
    "                   'tfidf_vec__min_df': [.0005,.001,.0015],}\n",
    "gs_tfidf_xgb = GridSearchCV(tfidf_xgb_pipe,tfidf_xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "de890259-c73b-4add-aec0-e8a42e2636e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;tfidf_vec&#x27;,\n",
       "                                        TfidfVectorizer(max_features=1000,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;xgb&#x27;,\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      callbacks=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      early_stopping_rounds=None,\n",
       "                                                      enable_categorical=False,\n",
       "                                                      eval_metric=None,\n",
       "                                                      feature_types=None,\n",
       "                                                      gam...\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      max_leaves=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints=None,\n",
       "                                                      n_estimators=100,\n",
       "                                                      n_jobs=None,\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      predictor=None,\n",
       "                                                      random_state=None, ...))]),\n",
       "             param_grid={&#x27;tfidf_vec__max_df&#x27;: [0.85, 0.9, 0.925],\n",
       "                         &#x27;tfidf_vec__min_df&#x27;: [0.0005, 0.001, 0.0015],\n",
       "                         &#x27;xgb__booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;],\n",
       "                         &#x27;xgb__eta&#x27;: [0.01, 0.015, 0.05]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;tfidf_vec&#x27;,\n",
       "                                        TfidfVectorizer(max_features=1000,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;xgb&#x27;,\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      callbacks=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      early_stopping_rounds=None,\n",
       "                                                      enable_categorical=False,\n",
       "                                                      eval_metric=None,\n",
       "                                                      feature_types=None,\n",
       "                                                      gam...\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      max_leaves=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints=None,\n",
       "                                                      n_estimators=100,\n",
       "                                                      n_jobs=None,\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      predictor=None,\n",
       "                                                      random_state=None, ...))]),\n",
       "             param_grid={&#x27;tfidf_vec__max_df&#x27;: [0.85, 0.9, 0.925],\n",
       "                         &#x27;tfidf_vec__min_df&#x27;: [0.0005, 0.001, 0.0015],\n",
       "                         &#x27;xgb__booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;],\n",
       "                         &#x27;xgb__eta&#x27;: [0.01, 0.015, 0.05]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf_vec&#x27;,\n",
       "                 TfidfVectorizer(max_features=1000, ngram_range=(1, 2),\n",
       "                                 stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000, ngram_range=(1, 2), stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidf_vec',\n",
       "                                        TfidfVectorizer(max_features=1000,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        stop_words='english')),\n",
       "                                       ('xgb',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      callbacks=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      early_stopping_rounds=None,\n",
       "                                                      enable_categorical=False,\n",
       "                                                      eval_metric=None,\n",
       "                                                      feature_types=None,\n",
       "                                                      gam...\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      max_leaves=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints=None,\n",
       "                                                      n_estimators=100,\n",
       "                                                      n_jobs=None,\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      predictor=None,\n",
       "                                                      random_state=None, ...))]),\n",
       "             param_grid={'tfidf_vec__max_df': [0.85, 0.9, 0.925],\n",
       "                         'tfidf_vec__min_df': [0.0005, 0.001, 0.0015],\n",
       "                         'xgb__booster': ['gbtree', 'gblinear'],\n",
       "                         'xgb__eta': [0.01, 0.015, 0.05]})"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tfidf_xgb.fit(X_train_lemmatized,y_train_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "653ba3d1-e39d-48e2-b048-68cec3adda92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf_vec__max_df': 0.925,\n",
       " 'tfidf_vec__min_df': 0.001,\n",
       " 'xgb__booster': 'gblinear',\n",
       " 'xgb__eta': 0.01}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tfidf_xgb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54428d31-0862-4e52-a2da-105853a3c0bf",
   "metadata": {},
   "source": [
    "gs_tfidf_xgb.best_params_\n",
    "{'tfidf_vec__max_df': 0.85,\n",
    " 'tfidf_vec__min_df': 0.001,\n",
    " 'xgb__alpha': 0,\n",
    " 'xgb__booster': 'gbtree',\n",
    " 'xgb__eta': 0.05,\n",
    " 'xgb__lambda': 0.1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f1e5e61c-7482-4222-adef-2d7824c0871c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9119318181818182, 0.8884381338742393)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tfidf_xgb.score(X_train_lemmatized,y_train_xgb),gs_tfidf_xgb.score(X_test_lemmatized,y_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14344a0-2933-4691-818c-79f5ddf09691",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_tfidf_xgb = GridSearchCV(tfidf_xgb_pipe,{'tfidf_vec__max_df': [0.9],\n",
    " 'tfidf_vec__min_df': [0.001],\n",
    " 'xgb__booster': ['gblinear'],\n",
    " 'xgb__eta': [0.005]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e72e58-178b-47c3-9533-423e58657793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_tfidf_xgb.fit(X_train_lemmatized,y_train_xgb)\n",
    "gs_tfidf_xgb.score(X_train_lemmatized,y_train_xgb),gs_tfidf_xgb.score(X_test_lemmatized,y_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "578c03a8-5f71-4e75-b838-7f0666450a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9119318181818182, 0.8884381338742393)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass in params from tuned xgb, tfidf\n",
    "\n",
    "# {'tfidf_vec__max_df': 0.925,\n",
    "#  'tfidf_vec__min_df': 0.001,\n",
    "#  'xgb__booster': 'gblinear',\n",
    "#  'xgb__eta': 0.01}\n",
    "\n",
    "# Instantiate Vectorizer with previously grid search optimized parameters\n",
    "tfidf_vec = TfidfVectorizer(stop_words='english', max_features=1_000,\n",
    "                             ngram_range=(1,2), max_df= 0.925, min_df= 0.001)\n",
    "\n",
    "title_pipe = Pipeline([\n",
    "    ('tfidf_vec', tfidf_vec),\n",
    "    ('xgb', xgboost.XGBClassifier(booster= 'gblinear',eta= 0.01))])\n",
    "\n",
    "title_pipe.fit(X_train_lemmatized, y_train_xgb)\n",
    "title_pipe.score(X_train_lemmatized, y_train_xgb), title_pipe.score(X_test_lemmatized, y_test_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c62d54-be9f-49a6-b916-60afc6b79290",
   "metadata": {},
   "source": [
    "Above, we see that the titles have more predictive value alone than do the statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec72988-b07d-4acc-9771-4d9d710c9ab1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### stacked models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "00974abe-8fb8-47c8-9afe-6da8b002ae1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-51 {color: black;background-color: white;}#sk-container-id-51 pre{padding: 0;}#sk-container-id-51 div.sk-toggleable {background-color: white;}#sk-container-id-51 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-51 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-51 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-51 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-51 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-51 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-51 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-51 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-51 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-51 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-51 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-51 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-51 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-51 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-51 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-51 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-51 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-51 div.sk-item {position: relative;z-index: 1;}#sk-container-id-51 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-51 div.sk-item::before, #sk-container-id-51 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-51 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-51 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-51 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-51 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-51 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-51 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-51 div.sk-label-container {text-align: center;}#sk-container-id-51 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-51 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-51\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf_vec&#x27;,\n",
       "                 TfidfVectorizer(max_df=0.925, max_features=1000, min_df=0.001,\n",
       "                                 ngram_range=(1, 2), stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=0.5, booster=&#x27;gblinear&#x27;,\n",
       "                               callbacks=None, colsample_bylevel=None,\n",
       "                               colsample_bynode=None, colsample_bytree=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eta=0.01,\n",
       "                               eval_metric=None, featu...ne, gamma=None,\n",
       "                               gpu_id=-1, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.5,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=None, predictor=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-98\" type=\"checkbox\" ><label for=\"sk-estimator-id-98\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf_vec&#x27;,\n",
       "                 TfidfVectorizer(max_df=0.925, max_features=1000, min_df=0.001,\n",
       "                                 ngram_range=(1, 2), stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=0.5, booster=&#x27;gblinear&#x27;,\n",
       "                               callbacks=None, colsample_bylevel=None,\n",
       "                               colsample_bynode=None, colsample_bytree=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eta=0.01,\n",
       "                               eval_metric=None, featu...ne, gamma=None,\n",
       "                               gpu_id=-1, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.5,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=None, predictor=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-99\" type=\"checkbox\" ><label for=\"sk-estimator-id-99\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.925, max_features=1000, min_df=0.001,\n",
       "                ngram_range=(1, 2), stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-100\" type=\"checkbox\" ><label for=\"sk-estimator-id-100\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.01, eval_metric=None,\n",
       "              feature_types=None, gamma=None, gpu_id=-1, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.5, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=None, predictor=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf_vec',\n",
       "                 TfidfVectorizer(max_df=0.925, max_features=1000, min_df=0.001,\n",
       "                                 ngram_range=(1, 2), stop_words='english')),\n",
       "                ('xgb',\n",
       "                 XGBClassifier(base_score=0.5, booster='gblinear',\n",
       "                               callbacks=None, colsample_bylevel=None,\n",
       "                               colsample_bynode=None, colsample_bytree=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eta=0.01,\n",
       "                               eval_metric=None, featu...ne, gamma=None,\n",
       "                               gpu_id=-1, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.5,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=None, predictor=None, ...))])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit models\n",
    "xgb_stats = xgboost.XGBClassifier()\n",
    "\n",
    "# Instantiate pipes\n",
    "# stats\n",
    "xgb_stats.fit(X_train_stats, y_train_binary)\n",
    "\n",
    "# title\n",
    "title_pipe.fit(X_train_lemmatized, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "4a782b17-3c4d-4a73-8853-5a3d86abe65f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_pred_train = pd.DataFrame()\n",
    "X_pred_train['stats'] = cross_val_predict(xgb_stats, X_train_stats, y_train_binary)\n",
    "X_pred_train['title'] = cross_val_predict(title_pipe, X_train_lemmatized, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ce55bb31-6b75-447b-9730-3124a6751d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 2 model: Logistic Regression\n",
    "lev2_logreg = LogisticRegressionCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "1d24f019-29b8-470c-867a-75083e7c273d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-52 {color: black;background-color: white;}#sk-container-id-52 pre{padding: 0;}#sk-container-id-52 div.sk-toggleable {background-color: white;}#sk-container-id-52 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-52 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-52 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-52 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-52 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-52 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-52 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-52 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-52 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-52 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-52 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-52 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-52 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-52 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-52 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-52 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-52 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-52 div.sk-item {position: relative;z-index: 1;}#sk-container-id-52 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-52 div.sk-item::before, #sk-container-id-52 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-52 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-52 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-52 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-52 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-52 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-52 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-52 div.sk-label-container {text-align: center;}#sk-container-id-52 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-52 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-52\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-101\" type=\"checkbox\" checked><label for=\"sk-estimator-id-101\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV()"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lev2_logreg.fit(X_pred_train, y_train_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "ed291485-ece9-4464-aba2-a834abc66479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8432088744588745"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lev2_logreg.score(X_pred_train,y_train_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5009d68a-265d-473c-8e97-b2091bfab46b",
   "metadata": {},
   "source": [
    "Conclusion: this form of stacking as led to worse results than seen with just the model fitted on the title data.  I will next attempt to use a column transformer to combine the title and stats data into one dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae572653-26cf-493d-889a-0bda91b41151",
   "metadata": {},
   "source": [
    "[source: strip characters from string in series](https://stackoverflow.com/questions/13682044/remove-unwanted-parts-from-strings-in-a-column)\n",
    "[source: remove punctuation](https://www.google.com/search?q=how+to+replace+punctuation+with+regular+expression+python&rlz=1C5CHFA_enUS983US983&oq=how+to+replace+punctuation+with+regular&aqs=chrome.1.69i57j33i160l2.10574j0j7&sourceid=chrome&ie=UTF-8#kpvalbx=_7SabY4OANaSs0PEP042roAM_32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8f840-7a2a-4d1c-af13-66e358789af5",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### Column transforming pipeline to generate final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "0bfd496b-c4ce-460a-a4df-8f42878e7a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "abc53861-197c-43e0-81d6-e9fe988bba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = pd.concat([X_train_lemmatized.rename('title'), X_train_stats], axis = 1)\n",
    "X_test_full = pd.concat([X_test_lemmatized.rename('title'), X_test_stats], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "4c124522-b15a-433b-a669-c6d8181fda73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_length</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>max_word_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>$</th>\n",
       "      <th>''</th>\n",
       "      <th>,</th>\n",
       "      <th>-LRB-</th>\n",
       "      <th>-RRB-</th>\n",
       "      <th>...</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>WDT</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "      <th>X</th>\n",
       "      <th>XX</th>\n",
       "      <th>_SP</th>\n",
       "      <th>``</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prove point + - karma nothing quality post</td>\n",
       "      <td>65</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>researcher identify origin serious illness child</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>way go level human need - think ai take u</td>\n",
       "      <td>95</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>former amazon exec reportedly paid $ run jeff ...</td>\n",
       "      <td>153</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>5.884615</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iphone pro max gb alpine green - unlocked rene...</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>6.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7387</th>\n",
       "      <td>supergps accurately pinpoint position within i...</td>\n",
       "      <td>85</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7388</th>\n",
       "      <td>email scrap legal - resistancephlcom</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7389</th>\n",
       "      <td>amazon ceo prime video attractive economics pa...</td>\n",
       "      <td>68</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7390</th>\n",
       "      <td>possible native payment system twitter</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>new study base foi request page found coca - c...</td>\n",
       "      <td>291</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>6.767442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7392 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  title_length  \\\n",
       "0            prove point + - karma nothing quality post            65   \n",
       "1      researcher identify origin serious illness child            70   \n",
       "2             way go level human need - think ai take u            95   \n",
       "3     former amazon exec reportedly paid $ run jeff ...           153   \n",
       "4     iphone pro max gb alpine green - unlocked rene...            67   \n",
       "...                                                 ...           ...   \n",
       "7387  supergps accurately pinpoint position within i...            85   \n",
       "7388               email scrap legal - resistancephlcom            44   \n",
       "7389  amazon ceo prime video attractive economics pa...            68   \n",
       "7390             possible native payment system twitter            42   \n",
       "7391  new study base foi request page found coca - c...           291   \n",
       "\n",
       "      title_word_count  max_word_length  avg_word_length  $  ''  ,  -LRB-  \\\n",
       "0                   13                7         5.000000  0   0  0      0   \n",
       "1                   10               11         7.000000  0   0  0      0   \n",
       "2                   20                8         4.750000  0   0  0      0   \n",
       "3                   26               10         5.884615  1   0  1      0   \n",
       "4                   11                8         6.090909  0   0  2      1   \n",
       "...                ...              ...              ... ..  .. ..    ...   \n",
       "7387                10               12         8.500000  0   1  0      0   \n",
       "7388                 6               17         7.333333  0   0  0      0   \n",
       "7389                10               10         6.800000  0   1  0      1   \n",
       "7390                 6                8         7.000000  0   0  0      0   \n",
       "7391                43               13         6.767442  0   0  1      0   \n",
       "\n",
       "      -RRB-  ...  VBZ  VERB  WDT  WP  WP$  WRB  X  XX  _SP  ``  \n",
       "0         0  ...    1     3    0   0    0    0  1   0    0   0  \n",
       "1         0  ...    0     1    0   0    0    0  0   0    0   0  \n",
       "2         0  ...    0     5    0   0    0    0  0   0    0   0  \n",
       "3         0  ...    0     3    1   0    0    0  0   0    0   0  \n",
       "4         1  ...    0     0    0   0    0    0  0   0    0   0  \n",
       "...     ...  ...  ...   ...  ...  ..  ...  ... ..  ..  ...  ..  \n",
       "7387      0  ...    1     1    0   0    0    0  0   0    0   1  \n",
       "7388      0  ...    1     1    0   0    0    0  1   0    0   0  \n",
       "7389      1  ...    1     1    0   0    0    0  0   0    0   1  \n",
       "7390      0  ...    0     0    0   0    0    0  0   0    0   0  \n",
       "7391      0  ...    1     4    1   0    0    0  0   0    0   0  \n",
       "\n",
       "[7392 rows x 72 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "680fa07f-a3c7-42b2-afa3-e68f96b818f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "75e47bbb-ff71-43fa-9cff-fb10fb10321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(stop_words='english', max_features=1_000,ngram_range=(1,2))\n",
    "\n",
    "text_transformer = tfidf_vec\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps = [('scaler',StandardScaler()),\n",
    "             ('polynomial', PolynomialFeatures(degree=2, interaction_only=True))\n",
    "            ]\n",
    ")\n",
    "text_features = 'title'\n",
    "numeric_features = X_train_full.columns[1:].values\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "    ('txt', text_transformer, text_features),\n",
    "    ('num', numeric_transformer, numeric_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "61fceb09-6610-4e38-8960-276e1518b808",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-63 {color: black;background-color: white;}#sk-container-id-63 pre{padding: 0;}#sk-container-id-63 div.sk-toggleable {background-color: white;}#sk-container-id-63 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-63 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-63 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-63 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-63 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-63 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-63 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-63 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-63 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-63 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-63 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-63 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-63 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-63 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-63 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-63 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-63 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-63 div.sk-item {position: relative;z-index: 1;}#sk-container-id-63 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-63 div.sk-item::before, #sk-container-id-63 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-63 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-63 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-63 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-63 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-63 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-63 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-63 div.sk-label-container {text-align: center;}#sk-container-id-63 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-63 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-63\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;txt&#x27;,\n",
       "                                                  TfidfVectorizer(max_features=1000,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               2),\n",
       "                                                                  stop_words=&#x27;english&#x27;),\n",
       "                                                  &#x27;title&#x27;),\n",
       "                                                 (&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler()),\n",
       "                                                                  (&#x27;polynomial&#x27;,\n",
       "                                                                   PolynomialFeatures(interaction_only=True))]),\n",
       "                                                  array([&#x27;title_length&#x27;, &#x27;title_word_count&#x27;, &#x27;max_word_length&#x27;,\n",
       "       &#x27;avg_word_length&#x27;, &#x27;$&#x27;, &quot;&#x27;&#x27;&quot;,...\n",
       "                               feature_types=None, gamma=0, gpu_id=-1,\n",
       "                               grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "                               interaction_constraints=&#x27;&#x27;,\n",
       "                               learning_rate=0.300000012, max_bin=256,\n",
       "                               max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "                               max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "                               random_state=0, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-178\" type=\"checkbox\" ><label for=\"sk-estimator-id-178\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;txt&#x27;,\n",
       "                                                  TfidfVectorizer(max_features=1000,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               2),\n",
       "                                                                  stop_words=&#x27;english&#x27;),\n",
       "                                                  &#x27;title&#x27;),\n",
       "                                                 (&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler()),\n",
       "                                                                  (&#x27;polynomial&#x27;,\n",
       "                                                                   PolynomialFeatures(interaction_only=True))]),\n",
       "                                                  array([&#x27;title_length&#x27;, &#x27;title_word_count&#x27;, &#x27;max_word_length&#x27;,\n",
       "       &#x27;avg_word_length&#x27;, &#x27;$&#x27;, &quot;&#x27;&#x27;&quot;,...\n",
       "                               feature_types=None, gamma=0, gpu_id=-1,\n",
       "                               grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "                               interaction_constraints=&#x27;&#x27;,\n",
       "                               learning_rate=0.300000012, max_bin=256,\n",
       "                               max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "                               max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "                               random_state=0, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-179\" type=\"checkbox\" ><label for=\"sk-estimator-id-179\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;txt&#x27;,\n",
       "                                 TfidfVectorizer(max_features=1000,\n",
       "                                                 ngram_range=(1, 2),\n",
       "                                                 stop_words=&#x27;english&#x27;),\n",
       "                                 &#x27;title&#x27;),\n",
       "                                (&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                                 (&#x27;polynomial&#x27;,\n",
       "                                                  PolynomialFeatures(interaction_only=True))]),\n",
       "                                 array([&#x27;title_length&#x27;, &#x27;title_word_count&#x27;, &#x27;max_word_length&#x27;,\n",
       "       &#x27;avg_word_length&#x27;, &#x27;$&#x27;, &quot;&#x27;&#x27;&quot;, &#x27;,&#x27;, &#x27;-LRB-&#x27;, &#x27;-RRB-&#x27;, &#x27;.&#x27;, &#x27;:&#x27;,\n",
       "       &#x27;ADD...AFX&#x27;, &#x27;AUX&#x27;, &#x27;CC&#x27;, &#x27;CCONJ&#x27;, &#x27;CD&#x27;,\n",
       "       &#x27;DET&#x27;, &#x27;DT&#x27;, &#x27;EX&#x27;, &#x27;FW&#x27;, &#x27;HYPH&#x27;, &#x27;IN&#x27;, &#x27;INTJ&#x27;, &#x27;JJ&#x27;, &#x27;JJR&#x27;, &#x27;JJS&#x27;,\n",
       "       &#x27;LS&#x27;, &#x27;MD&#x27;, &#x27;NFP&#x27;, &#x27;NN&#x27;, &#x27;NNP&#x27;, &#x27;NNPS&#x27;, &#x27;NNS&#x27;, &#x27;NOUN&#x27;, &#x27;NUM&#x27;,\n",
       "       &#x27;PART&#x27;, &#x27;PDT&#x27;, &#x27;POS&#x27;, &#x27;PRON&#x27;, &#x27;PROPN&#x27;, &#x27;PRP&#x27;, &#x27;PRP$&#x27;, &#x27;PUNCT&#x27;,\n",
       "       &#x27;RB&#x27;, &#x27;RBR&#x27;, &#x27;RBS&#x27;, &#x27;RP&#x27;, &#x27;SCONJ&#x27;, &#x27;SPACE&#x27;, &#x27;SYM&#x27;, &#x27;TO&#x27;, &#x27;UH&#x27;,\n",
       "       &#x27;VB&#x27;, &#x27;VBD&#x27;, &#x27;VBG&#x27;, &#x27;VBN&#x27;, &#x27;VBP&#x27;, &#x27;VBZ&#x27;, &#x27;VERB&#x27;, &#x27;WDT&#x27;, &#x27;WP&#x27;,\n",
       "       &#x27;WP$&#x27;, &#x27;WRB&#x27;, &#x27;X&#x27;, &#x27;XX&#x27;, &#x27;_SP&#x27;, &#x27;``&#x27;], dtype=object))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-180\" type=\"checkbox\" ><label for=\"sk-estimator-id-180\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">txt</label><div class=\"sk-toggleable__content\"><pre>title</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-181\" type=\"checkbox\" ><label for=\"sk-estimator-id-181\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000, ngram_range=(1, 2), stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-182\" type=\"checkbox\" ><label for=\"sk-estimator-id-182\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;title_length&#x27; &#x27;title_word_count&#x27; &#x27;max_word_length&#x27; &#x27;avg_word_length&#x27; &#x27;$&#x27;\n",
       " &quot;&#x27;&#x27;&quot; &#x27;,&#x27; &#x27;-LRB-&#x27; &#x27;-RRB-&#x27; &#x27;.&#x27; &#x27;:&#x27; &#x27;ADD&#x27; &#x27;ADJ&#x27; &#x27;ADP&#x27; &#x27;ADV&#x27; &#x27;AFX&#x27; &#x27;AUX&#x27; &#x27;CC&#x27;\n",
       " &#x27;CCONJ&#x27; &#x27;CD&#x27; &#x27;DET&#x27; &#x27;DT&#x27; &#x27;EX&#x27; &#x27;FW&#x27; &#x27;HYPH&#x27; &#x27;IN&#x27; &#x27;INTJ&#x27; &#x27;JJ&#x27; &#x27;JJR&#x27; &#x27;JJS&#x27;\n",
       " &#x27;LS&#x27; &#x27;MD&#x27; &#x27;NFP&#x27; &#x27;NN&#x27; &#x27;NNP&#x27; &#x27;NNPS&#x27; &#x27;NNS&#x27; &#x27;NOUN&#x27; &#x27;NUM&#x27; &#x27;PART&#x27; &#x27;PDT&#x27; &#x27;POS&#x27;\n",
       " &#x27;PRON&#x27; &#x27;PROPN&#x27; &#x27;PRP&#x27; &#x27;PRP$&#x27; &#x27;PUNCT&#x27; &#x27;RB&#x27; &#x27;RBR&#x27; &#x27;RBS&#x27; &#x27;RP&#x27; &#x27;SCONJ&#x27; &#x27;SPACE&#x27;\n",
       " &#x27;SYM&#x27; &#x27;TO&#x27; &#x27;UH&#x27; &#x27;VB&#x27; &#x27;VBD&#x27; &#x27;VBG&#x27; &#x27;VBN&#x27; &#x27;VBP&#x27; &#x27;VBZ&#x27; &#x27;VERB&#x27; &#x27;WDT&#x27; &#x27;WP&#x27;\n",
       " &#x27;WP$&#x27; &#x27;WRB&#x27; &#x27;X&#x27; &#x27;XX&#x27; &#x27;_SP&#x27; &#x27;``&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-183\" type=\"checkbox\" ><label for=\"sk-estimator-id-183\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-184\" type=\"checkbox\" ><label for=\"sk-estimator-id-184\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(interaction_only=True)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-185\" type=\"checkbox\" ><label for=\"sk-estimator-id-185\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('txt',\n",
       "                                                  TfidfVectorizer(max_features=1000,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               2),\n",
       "                                                                  stop_words='english'),\n",
       "                                                  'title'),\n",
       "                                                 ('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler()),\n",
       "                                                                  ('polynomial',\n",
       "                                                                   PolynomialFeatures(interaction_only=True))]),\n",
       "                                                  array(['title_length', 'title_word_count', 'max_word_length',\n",
       "       'avg_word_length', '$', \"''\",...\n",
       "                               feature_types=None, gamma=0, gpu_id=-1,\n",
       "                               grow_policy='depthwise', importance_type=None,\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_bin=256,\n",
       "                               max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "                               max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "                               random_state=0, ...))])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline(\n",
    "    steps = [('preprocessor', preprocessor), ('classifier', xgboost.XGBClassifier(max_depth=6))]\n",
    ")\n",
    "clf.fit (X_train_full, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "5b8eb132-a90c-4ba1-a289-053739a08a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9552218614718615, 0.8713995943204869)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train_full,y_train_binary clf.score(X_test_full,y_test_binary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
